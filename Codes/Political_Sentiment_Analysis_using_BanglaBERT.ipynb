{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpCCLTmDhcQ_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,log_loss,jaccard_score,roc_auc_score,classification_report,confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yHBqBhGm-wG"
   },
   "source": [
    "# **Train Dataset Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "ZsRJ27UGiB7C",
    "outputId": "2fa25d17-b157-4b42-9285-5ac6aaa1ec7d"
   },
   "outputs": [],
   "source": [
    "# Read the csv file into a DataFrame\n",
    "train_data = pd.read_csv('E:\\\\New folder\\\\train.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtT2V9ZpnFZD",
    "outputId": "13b8e8e4-bf28-41e9-cb19-be6e08734195"
   },
   "outputs": [],
   "source": [
    "label_counts = train_data['sentiment'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqCXz3LqnN-s"
   },
   "source": [
    "# **Test Dataset Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "GzOq-tdml8lu",
    "outputId": "9af72269-bf72-4504-aafe-a61c36b0c1d2"
   },
   "outputs": [],
   "source": [
    "# Read the csv file into a DataFrame\n",
    "test_data = pd.read_csv(\"E:\\\\New folder\\\\test.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-JbtPsvmQY2",
    "outputId": "a5fbc731-943b-4951-c04c-a92bafa9077b"
   },
   "outputs": [],
   "source": [
    "label_counts = test_data['sentiment'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_9WwH6JnTOu"
   },
   "source": [
    "# **Validation Dataset Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "jGvXdzYgl9Pd",
    "outputId": "333dd8c9-77b9-4841-81d8-47d46969ba87"
   },
   "outputs": [],
   "source": [
    "# Read the csv file into a DataFrame\n",
    "val_data = pd.read_csv(\"E:\\\\New folder\\\\validation.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfgsQ4NfnWZC",
    "outputId": "a42ecf23-19d5-4fd0-8fa2-12c558adb939"
   },
   "outputs": [],
   "source": [
    "label_counts = val_data['sentiment'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjvYiqfCuvQ3"
   },
   "source": [
    "# **Visualization of Label Distribution in Train Dataset**\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "z-Zk_j66jTQL",
    "outputId": "8f435f23-4b03-48f0-8e78-089e51103643"
   },
   "outputs": [],
   "source": [
    "label_counts = train_data['sentiment'].value_counts()\n",
    "\n",
    "# Define custom colors for the bars\n",
    "custom_colors = ['#73aeea', '#2595b0']\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Create bar plot with grid\n",
    "bars = plt.bar(label_counts.index, label_counts.values, color=custom_colors)\n",
    "\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Sentiment Distribution on Train Dataset', fontdict=font)\n",
    "plt.xlabel('Label', fontdict=font)\n",
    "plt.ylabel('Count', fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(label_counts.index, label_counts.index, fontdict=font)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "\n",
    "# Adding annotations (count values) on top of each bar\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontdict=font)\n",
    "\n",
    "# Show the plot\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Political_train.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lual0D29r14T"
   },
   "source": [
    "# **Visualization of Label Distribution in Test Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "Ri7Fz2d_rxlq",
    "outputId": "adebb97d-c411-4169-f0e1-c06ee6e1283c"
   },
   "outputs": [],
   "source": [
    "label_counts = test_data['sentiment'].value_counts()\n",
    "\n",
    "# Define custom colors for the bars\n",
    "custom_colors = ['#73aeea', '#2595b0']\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Create bar plot with grid\n",
    "bars = plt.bar(label_counts.index, label_counts.values, color=custom_colors)\n",
    "\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Sentiment Distribution on Test Dataset', fontdict=font)\n",
    "plt.xlabel('Label', fontdict=font)\n",
    "plt.ylabel('Count', fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(label_counts.index, label_counts.index, fontdict=font)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "\n",
    "# Adding annotations (count values) on top of each bar\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontdict=font)\n",
    "\n",
    "# Show the plot\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Political_test.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DY66nPRtlgR"
   },
   "source": [
    "# **Visualization of Label Distribution in Validation Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "m_DOyy0nrx6a",
    "outputId": "9d503dd5-78d1-41c5-fa6c-7e105f5e41a4"
   },
   "outputs": [],
   "source": [
    "label_counts = val_data['sentiment'].value_counts()\n",
    "\n",
    "# Define custom colors for the bars\n",
    "custom_colors = ['#73aeea', '#2595b0']\n",
    "\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Create bar plot with grid\n",
    "bars = plt.bar(label_counts.index, label_counts.values, color=custom_colors)\n",
    "\n",
    "\n",
    "# Set title and axis labels using custom fontdict\n",
    "plt.title('Sentiment Distribution on Validation Dataset', fontdict=font)\n",
    "plt.xlabel('Label', fontdict=font)\n",
    "plt.ylabel('Count', fontdict=font)\n",
    "\n",
    "# Set custom font for ticks on both x and y axes\n",
    "plt.xticks(label_counts.index, label_counts.index, fontdict=font)\n",
    "plt.yticks(fontname='Serif', fontsize=10)\n",
    "\n",
    "# Adding annotations (count values) on top of each bar\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),\n",
    "             ha='center', va='bottom', fontdict=font)\n",
    "\n",
    "# Show the plot\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Political_validation.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaIoScyCznU-",
    "outputId": "bd352d16-bf86-4e4c-91f5-b415d843e738"
   },
   "outputs": [],
   "source": [
    "print(f\"Length of train dataset: {len(train_data)}\")\n",
    "print(f\"Length of test dataset: {len(test_data)}\")\n",
    "print(f\"Length of validation dataset: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMdPz2c9GkPU"
   },
   "source": [
    "# **Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBsNpLBbxutl"
   },
   "outputs": [],
   "source": [
    "class BanglaPoliticalSentimentDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Define a mapping for sentiment labels\n",
    "        self.sentiment_map = {\"Positive\": 1, \"Negative\": 0}  # You can add more sentiments if needed\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content = self.data.iloc[idx]['short_description']\n",
    "        label = self.data.iloc[idx]['sentiment']\n",
    "\n",
    "        # Convert sentiment label to integer using the mapping\n",
    "        label = self.sentiment_map[label]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            content,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(label, dtype=torch.long) #torch.nn.CrossEntropyLoss expects the target labels to be torch.LongTensor.\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11UrYcBqC4m_",
    "outputId": "0b3cca05-22d7-474e-c08e-3e0200a92546"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/csebuetnlp/normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP6-xV1nC5Fo",
    "outputId": "6a707fff-5fce-47cf-b1d1-faf04b3b8957"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRkXL79GC5KW",
    "outputId": "32a46171-0adb-420e-8f12-15728008a07a"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crwbxj6oC86u",
    "outputId": "a74bda68-2fcd-462d-c769-bbd1d8942080"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kErGt9ZpGwoJ"
   },
   "source": [
    "# **BanglaBERT model and its tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkgKQFwB0T-m",
    "outputId": "08597d41-6d5b-44d7-944a-cbc6f2a3ebde"
   },
   "outputs": [],
   "source": [
    "# Model loading\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n",
    "num_classes = 2  #number of classes in our dataset\n",
    "\n",
    "model_name = \"csebuetnlp/banglabert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aLIRdgbyWOq",
    "outputId": "e112c75a-4d8b-44df-a83c-42757a9bd5d3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Xez_VJGThM"
   },
   "source": [
    "# **Apply normalization to the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYQpkUjCGSUC"
   },
   "outputs": [],
   "source": [
    "# Apply normalization to the datasets\n",
    "train_data['short_description'] = train_data['short_description'].apply(normalize)\n",
    "test_data['short_description'] = test_data['short_description'].apply(normalize)\n",
    "val_data['short_description'] = val_data['short_description'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9-MGZkeG4-0"
   },
   "source": [
    "# **Custom dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-tLeV43ynJu"
   },
   "outputs": [],
   "source": [
    "# Define custom datasets\n",
    "train_dataset = BanglaPoliticalSentimentDataset(train_data, tokenizer)\n",
    "val_dataset = BanglaPoliticalSentimentDataset(val_data, tokenizer)\n",
    "test_dataset = BanglaPoliticalSentimentDataset(test_data, tokenizer)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=6, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47cXtXdL_nMo"
   },
   "source": [
    "# **Train Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20zI6bRN_bFu",
    "outputId": "6406d7ab-7303-4566-fab6-3c8e2368d9d6"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "#     # Print information\n",
    "#     print(\"Input IDs:\", input_ids)\n",
    "#     print(\"Attention Mask:\", attention_mask)\n",
    "#     print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "#     # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pZ42AGhB26D"
   },
   "source": [
    "# **Test Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYoY4WyfBtc5",
    "outputId": "b9b5de66-d376-4ed5-a555-d30b70378198"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "#     print(\"Input IDs:\", input_ids)\n",
    "#     print(\"Attention Mask:\", attention_mask)\n",
    "#     print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMZs9N5zB6Vk"
   },
   "source": [
    "# **Validation Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4vKjTD1BtqP",
    "outputId": "de11621f-7edc-46fe-dd32-875efbc0df59"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "#     print(\"Input IDs:\", input_ids)\n",
    "#     print(\"Attention Mask:\", attention_mask)\n",
    "#     print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGPRkviKBl6z"
   },
   "source": [
    "# **Train Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2QNeEF0_juI",
    "outputId": "4d5640f0-c3e6-4990-ff85-04a355bf7982"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    #print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    #print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    #print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZlYAfUVCJcB"
   },
   "source": [
    "# **Test Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "md_OyaoxCDWx",
    "outputId": "2646e84f-3b79-4123-f143-4ec301ebd024"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    #print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    #print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    #print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiqthc3zCQCc"
   },
   "source": [
    "# **Validation Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7jR08HkCDcb",
    "outputId": "15b89a99-2ed5-4118-cc5e-3d0b9fbd76f2"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    #print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    #print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    #print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcpL2A4_GSiU"
   },
   "source": [
    "# **Optimizer and Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zusl9Tf-1gmX"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "learning_rate = 2e-5\n",
    "# Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUjXcnbuGVwN"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "i8C0VQyb1gs4",
    "outputId": "c5763b52-5766-4b60-8d06-266d1df23f00"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "gradient_accumulation_steps = 16  # Accumulate gradients over 4 steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start time of the epoch\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Average training loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Wrap val_loader with tqdm for progress bar\n",
    "    for batch in tqdm(val_loader, desc=f'Validation', leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "\n",
    "        val_preds.extend(predicted.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Calculate and print epoch training time\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} completed in {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWaLvTInGDsm"
   },
   "source": [
    "# **Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "by3TpLW11gwW",
    "outputId": "c4509351-78fc-493d-a96d-cfedde61ef57"
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "test_labels = []\n",
    "test_probs = []  # Store predicted probabilities\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Assuming our model directly outputs logits\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)  # Softmax to get probabilities\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probabilities.cpu().numpy())  # Append predicted probabilities\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "test_precision = precision_score(test_labels, test_preds, average='macro')\n",
    "test_recall = recall_score(test_labels, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LAZtet934_WM",
    "outputId": "4cdcf9e0-0fe4-47c9-8a16-fb36c3570908"
   },
   "outputs": [],
   "source": [
    "print(test_preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMJnxfow5B6E"
   },
   "source": [
    "# **Printing the evaluation metric results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k46PXStc4yhY",
    "outputId": "5744b9fc-3a5f-44cc-9288-7d6c74b4287d"
   },
   "outputs": [],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLlqZy6zHT-2"
   },
   "source": [
    "# **Confusion Matrix of Political_Sentiment_Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7LAaopHgGZrx",
    "outputId": "776cca3c-e0e1-4602-a207-09b045c5a9bb"
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(\"crest\", as_cmap=True)# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 15}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,vmin = 0,vmax = 250,\n",
    "                      xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'],annot_kws={\"family\": \"Serif\",'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font)\n",
    "heatmap.set_ylabel('True Labels', fontdict=font)\n",
    "heatmap.set_title('Political Sentiment Analysis', fontdict=font)\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Count', fontdict=font)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Bangla_Bert_Political_cm.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwfk74VtF5_i"
   },
   "source": [
    "# **Store predicted results to a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hR1jVzjFAVsW"
   },
   "outputs": [],
   "source": [
    "# Combine the lists into a DataFrame\n",
    "data = {'Content': test_data['short_description'],\n",
    "        'True_Labels': test_data['sentiment'],\n",
    "        'Predicted_Labels': test_preds}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('banglabert_predicted_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKmzr6JUCwxb"
   },
   "source": [
    "# **save model, tokenizer, and classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "76GYXJkmCtOh",
    "outputId": "d38c5038-48ca-4d60-b029-1d55ad852e09"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('Bangla_political_Text_BanglaBERT_Model.pt')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('Bangla_political_Text_BanglaBERT_Tokenizer.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97CRLpZdE7gR"
   },
   "source": [
    "# **load model, tokenizer, and classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sE__b493E03Q",
    "outputId": "8893a6e8-06a4-4b65-eed7-6257eff1e1dc"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model.from_pretrained('Bangla_political_Text_BanglaBERT_Model.pt')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer.from_pretrained('Bangla_political_Text_BanglaBERT_Tokenizer.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
